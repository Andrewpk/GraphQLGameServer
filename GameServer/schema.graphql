schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"Boolean expression to compare columns of type \"Int\". All fields are combined with logical 'AND'."
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"Boolean expression to compare columns of type \"String\". All fields are combined with logical 'AND'."
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String
  "does the column match the given case-insensitive pattern"
  _ilike: String
  _in: [String!]
  "does the column match the given POSIX regular expression, case insensitive"
  _iregex: String
  _is_null: Boolean
  "does the column match the given pattern"
  _like: String
  _lt: String
  _lte: String
  _neq: String
  "does the column NOT match the given case-insensitive pattern"
  _nilike: String
  _nin: [String!]
  "does the column NOT match the given POSIX regular expression, case insensitive"
  _niregex: String
  "does the column NOT match the given pattern"
  _nlike: String
  "does the column NOT match the given POSIX regular expression, case sensitive"
  _nregex: String
  "does the column NOT match the given SQL regular expression"
  _nsimilar: String
  "does the column match the given POSIX regular expression, case sensitive"
  _regex: String
  "does the column match the given SQL regular expression"
  _similar: String
}

scalar bigint

"Boolean expression to compare columns of type \"bigint\". All fields are combined with logical 'AND'."
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

"ordering argument of a cursor"
enum cursor_ordering {
  "ascending ordering of the cursor"
  ASC
  "descending ordering of the cursor"
  DESC
}

"columns and relationships of \"flappy.high_score\""
type flappy_high_score {
  created_at: timestamptz!
  id: bigint!
  name: String!
  score: Int!
}

"aggregated selection of \"flappy.high_score\""
type flappy_high_score_aggregate {
  aggregate: flappy_high_score_aggregate_fields
  nodes: [flappy_high_score!]!
}

"aggregate fields of \"flappy.high_score\""
type flappy_high_score_aggregate_fields {
  avg: flappy_high_score_avg_fields
  count(columns: [flappy_high_score_select_column!] distinct: Boolean): Int!
  max: flappy_high_score_max_fields
  min: flappy_high_score_min_fields
  stddev: flappy_high_score_stddev_fields
  stddev_pop: flappy_high_score_stddev_pop_fields
  stddev_samp: flappy_high_score_stddev_samp_fields
  sum: flappy_high_score_sum_fields
  var_pop: flappy_high_score_var_pop_fields
  var_samp: flappy_high_score_var_samp_fields
  variance: flappy_high_score_variance_fields
}

"aggregate avg on columns"
type flappy_high_score_avg_fields {
  id: Float
  score: Float
}

"Boolean expression to filter rows from the table \"flappy.high_score\". All fields are combined with a logical 'AND'."
input flappy_high_score_bool_exp {
  _and: [flappy_high_score_bool_exp!]
  _not: flappy_high_score_bool_exp
  _or: [flappy_high_score_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: bigint_comparison_exp
  name: String_comparison_exp
  score: Int_comparison_exp
}

"unique or primary key constraints on table \"flappy.high_score\""
enum flappy_high_score_constraint {
  "unique or primary key constraint on columns \"id\""
  high_score_pkey
}

"input type for incrementing numeric columns in table \"flappy.high_score\""
input flappy_high_score_inc_input {
  id: bigint
  score: Int
}

"input type for inserting data into table \"flappy.high_score\""
input flappy_high_score_insert_input {
  created_at: timestamptz
  id: bigint
  name: String
  score: Int
}

"aggregate max on columns"
type flappy_high_score_max_fields {
  created_at: timestamptz
  id: bigint
  name: String
  score: Int
}

"aggregate min on columns"
type flappy_high_score_min_fields {
  created_at: timestamptz
  id: bigint
  name: String
  score: Int
}

"response of any mutation on the table \"flappy.high_score\""
type flappy_high_score_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [flappy_high_score!]!
}

"on_conflict condition type for table \"flappy.high_score\""
input flappy_high_score_on_conflict {
  constraint: flappy_high_score_constraint!
  update_columns: [flappy_high_score_update_column!]! = [  ]
  where: flappy_high_score_bool_exp
}

"Ordering options when selecting data from \"flappy.high_score\"."
input flappy_high_score_order_by {
  created_at: order_by
  id: order_by
  name: order_by
  score: order_by
}

"primary key columns input for table: flappy.high_score"
input flappy_high_score_pk_columns_input {
  id: bigint!
}

"select columns of table \"flappy.high_score\""
enum flappy_high_score_select_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  name
  "column name"
  score
}

"input type for updating data in table \"flappy.high_score\""
input flappy_high_score_set_input {
  created_at: timestamptz
  id: bigint
  name: String
  score: Int
}

"aggregate stddev on columns"
type flappy_high_score_stddev_fields {
  id: Float
  score: Float
}

"aggregate stddev_pop on columns"
type flappy_high_score_stddev_pop_fields {
  id: Float
  score: Float
}

"aggregate stddev_samp on columns"
type flappy_high_score_stddev_samp_fields {
  id: Float
  score: Float
}

"Streaming cursor of the table \"flappy_high_score\""
input flappy_high_score_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: flappy_high_score_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input flappy_high_score_stream_cursor_value_input {
  created_at: timestamptz
  id: bigint
  name: String
  score: Int
}

"aggregate sum on columns"
type flappy_high_score_sum_fields {
  id: bigint
  score: Int
}

"update columns of table \"flappy.high_score\""
enum flappy_high_score_update_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  name
  "column name"
  score
}

input flappy_high_score_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: flappy_high_score_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: flappy_high_score_set_input
  "filter the rows which have to be updated"
  where: flappy_high_score_bool_exp!
}

"aggregate var_pop on columns"
type flappy_high_score_var_pop_fields {
  id: Float
  score: Float
}

"aggregate var_samp on columns"
type flappy_high_score_var_samp_fields {
  id: Float
  score: Float
}

"aggregate variance on columns"
type flappy_high_score_variance_fields {
  id: Float
  score: Float
}

scalar jsonb

input jsonb_cast_exp {
  String: String_comparison_exp
}

"Boolean expression to compare columns of type \"jsonb\". All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
  _cast: jsonb_cast_exp
  "is the column contained in the given json value"
  _contained_in: jsonb
  "does the column contain the given json value at the top level"
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb
  "does the string exist as a top-level key in the column"
  _has_key: String
  "do all of these strings exist as top-level keys in the column"
  _has_keys_all: [String!]
  "do any of these strings exist as top-level keys in the column"
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"columns and relationships of \"list\""
type list {
  created_at: timestamptz!
  creator: bigint!
  id: bigint!
  "An array relationship"
  list_items("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "An aggregate relationship"
  list_items_aggregate("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): list_item_aggregate!
  title: String!
  updated_at: timestamptz
  "An object relationship"
  user: user!
}

"aggregated selection of \"list\""
type list_aggregate {
  aggregate: list_aggregate_fields
  nodes: [list!]!
}

input list_aggregate_bool_exp {
  count: list_aggregate_bool_exp_count
}

input list_aggregate_bool_exp_count {
  arguments: [list_select_column!]
  distinct: Boolean
  filter: list_bool_exp
  predicate: Int_comparison_exp!
}

"aggregate fields of \"list\""
type list_aggregate_fields {
  avg: list_avg_fields
  count(columns: [list_select_column!] distinct: Boolean): Int!
  max: list_max_fields
  min: list_min_fields
  stddev: list_stddev_fields
  stddev_pop: list_stddev_pop_fields
  stddev_samp: list_stddev_samp_fields
  sum: list_sum_fields
  var_pop: list_var_pop_fields
  var_samp: list_var_samp_fields
  variance: list_variance_fields
}

"order by aggregate values of table \"list\""
input list_aggregate_order_by {
  avg: list_avg_order_by
  count: order_by
  max: list_max_order_by
  min: list_min_order_by
  stddev: list_stddev_order_by
  stddev_pop: list_stddev_pop_order_by
  stddev_samp: list_stddev_samp_order_by
  sum: list_sum_order_by
  var_pop: list_var_pop_order_by
  var_samp: list_var_samp_order_by
  variance: list_variance_order_by
}

"input type for inserting array relation for remote table \"list\""
input list_arr_rel_insert_input {
  data: [list_insert_input!]!
  "upsert condition"
  on_conflict: list_on_conflict
}

"aggregate avg on columns"
type list_avg_fields {
  creator: Float
  id: Float
}

"order by avg() on columns of table \"list\""
input list_avg_order_by {
  creator: order_by
  id: order_by
}

"Boolean expression to filter rows from the table \"list\". All fields are combined with a logical 'AND'."
input list_bool_exp {
  _and: [list_bool_exp!]
  _not: list_bool_exp
  _or: [list_bool_exp!]
  created_at: timestamptz_comparison_exp
  creator: bigint_comparison_exp
  id: bigint_comparison_exp
  list_items: list_item_bool_exp
  list_items_aggregate: list_item_aggregate_bool_exp
  title: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  user: user_bool_exp
}

"unique or primary key constraints on table \"list\""
enum list_constraint {
  "unique or primary key constraint on columns \"id\""
  list_pkey
}

"input type for incrementing numeric columns in table \"list\""
input list_inc_input {
  creator: bigint
  id: bigint
}

"input type for inserting data into table \"list\""
input list_insert_input {
  created_at: timestamptz
  creator: bigint
  id: bigint
  list_items: list_item_arr_rel_insert_input
  title: String
  updated_at: timestamptz
  user: user_obj_rel_insert_input
}

"columns and relationships of \"list_item\""
type list_item {
  body("JSON select path" path: String): jsonb!
  created_at: timestamptz!
  creator: bigint!
  id: bigint!
  list: bigint!
  "An object relationship"
  listByList: list!
  "An object relationship"
  list_item_type: list_item_type!
  title: String
  type: list_item_type_enum!
  updated_at: timestamptz
  "An object relationship"
  user: user!
}

"aggregated selection of \"list_item\""
type list_item_aggregate {
  aggregate: list_item_aggregate_fields
  nodes: [list_item!]!
}

input list_item_aggregate_bool_exp {
  count: list_item_aggregate_bool_exp_count
}

input list_item_aggregate_bool_exp_count {
  arguments: [list_item_select_column!]
  distinct: Boolean
  filter: list_item_bool_exp
  predicate: Int_comparison_exp!
}

"aggregate fields of \"list_item\""
type list_item_aggregate_fields {
  avg: list_item_avg_fields
  count(columns: [list_item_select_column!] distinct: Boolean): Int!
  max: list_item_max_fields
  min: list_item_min_fields
  stddev: list_item_stddev_fields
  stddev_pop: list_item_stddev_pop_fields
  stddev_samp: list_item_stddev_samp_fields
  sum: list_item_sum_fields
  var_pop: list_item_var_pop_fields
  var_samp: list_item_var_samp_fields
  variance: list_item_variance_fields
}

"order by aggregate values of table \"list_item\""
input list_item_aggregate_order_by {
  avg: list_item_avg_order_by
  count: order_by
  max: list_item_max_order_by
  min: list_item_min_order_by
  stddev: list_item_stddev_order_by
  stddev_pop: list_item_stddev_pop_order_by
  stddev_samp: list_item_stddev_samp_order_by
  sum: list_item_sum_order_by
  var_pop: list_item_var_pop_order_by
  var_samp: list_item_var_samp_order_by
  variance: list_item_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input list_item_append_input {
  body: jsonb
}

"input type for inserting array relation for remote table \"list_item\""
input list_item_arr_rel_insert_input {
  data: [list_item_insert_input!]!
  "upsert condition"
  on_conflict: list_item_on_conflict
}

"aggregate avg on columns"
type list_item_avg_fields {
  creator: Float
  id: Float
  list: Float
}

"order by avg() on columns of table \"list_item\""
input list_item_avg_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"Boolean expression to filter rows from the table \"list_item\". All fields are combined with a logical 'AND'."
input list_item_bool_exp {
  _and: [list_item_bool_exp!]
  _not: list_item_bool_exp
  _or: [list_item_bool_exp!]
  body: jsonb_comparison_exp
  created_at: timestamptz_comparison_exp
  creator: bigint_comparison_exp
  id: bigint_comparison_exp
  list: bigint_comparison_exp
  listByList: list_bool_exp
  list_item_type: list_item_type_bool_exp
  title: String_comparison_exp
  type: list_item_type_enum_comparison_exp
  updated_at: timestamptz_comparison_exp
  user: user_bool_exp
}

"unique or primary key constraints on table \"list_item\""
enum list_item_constraint {
  "unique or primary key constraint on columns \"id\""
  list_item_pkey
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input list_item_delete_at_path_input {
  body: [String!]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input list_item_delete_elem_input {
  body: Int
}

"delete key\/value pair or string element. key\/value pairs are matched based on their key value"
input list_item_delete_key_input {
  body: String
}

"input type for incrementing numeric columns in table \"list_item\""
input list_item_inc_input {
  creator: bigint
  id: bigint
  list: bigint
}

"input type for inserting data into table \"list_item\""
input list_item_insert_input {
  body: jsonb
  created_at: timestamptz
  creator: bigint
  id: bigint
  list: bigint
  listByList: list_obj_rel_insert_input
  list_item_type: list_item_type_obj_rel_insert_input
  title: String
  type: list_item_type_enum
  updated_at: timestamptz
  user: user_obj_rel_insert_input
}

"aggregate max on columns"
type list_item_max_fields {
  created_at: timestamptz
  creator: bigint
  id: bigint
  list: bigint
  title: String
  updated_at: timestamptz
}

"order by max() on columns of table \"list_item\""
input list_item_max_order_by {
  created_at: order_by
  creator: order_by
  id: order_by
  list: order_by
  title: order_by
  updated_at: order_by
}

"aggregate min on columns"
type list_item_min_fields {
  created_at: timestamptz
  creator: bigint
  id: bigint
  list: bigint
  title: String
  updated_at: timestamptz
}

"order by min() on columns of table \"list_item\""
input list_item_min_order_by {
  created_at: order_by
  creator: order_by
  id: order_by
  list: order_by
  title: order_by
  updated_at: order_by
}

"response of any mutation on the table \"list_item\""
type list_item_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [list_item!]!
}

"on_conflict condition type for table \"list_item\""
input list_item_on_conflict {
  constraint: list_item_constraint!
  update_columns: [list_item_update_column!]! = [  ]
  where: list_item_bool_exp
}

"Ordering options when selecting data from \"list_item\"."
input list_item_order_by {
  body: order_by
  created_at: order_by
  creator: order_by
  id: order_by
  list: order_by
  listByList: list_order_by
  list_item_type: list_item_type_order_by
  title: order_by
  type: order_by
  updated_at: order_by
  user: user_order_by
}

"primary key columns input for table: list_item"
input list_item_pk_columns_input {
  id: bigint!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input list_item_prepend_input {
  body: jsonb
}

"select columns of table \"list_item\""
enum list_item_select_column {
  "column name"
  body
  "column name"
  created_at
  "column name"
  creator
  "column name"
  id
  "column name"
  list
  "column name"
  title
  "column name"
  type
  "column name"
  updated_at
}

"input type for updating data in table \"list_item\""
input list_item_set_input {
  body: jsonb
  created_at: timestamptz
  creator: bigint
  id: bigint
  list: bigint
  title: String
  type: list_item_type_enum
  updated_at: timestamptz
}

"aggregate stddev on columns"
type list_item_stddev_fields {
  creator: Float
  id: Float
  list: Float
}

"order by stddev() on columns of table \"list_item\""
input list_item_stddev_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"aggregate stddev_pop on columns"
type list_item_stddev_pop_fields {
  creator: Float
  id: Float
  list: Float
}

"order by stddev_pop() on columns of table \"list_item\""
input list_item_stddev_pop_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"aggregate stddev_samp on columns"
type list_item_stddev_samp_fields {
  creator: Float
  id: Float
  list: Float
}

"order by stddev_samp() on columns of table \"list_item\""
input list_item_stddev_samp_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"Streaming cursor of the table \"list_item\""
input list_item_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: list_item_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input list_item_stream_cursor_value_input {
  body: jsonb
  created_at: timestamptz
  creator: bigint
  id: bigint
  list: bigint
  title: String
  type: list_item_type_enum
  updated_at: timestamptz
}

"aggregate sum on columns"
type list_item_sum_fields {
  creator: bigint
  id: bigint
  list: bigint
}

"order by sum() on columns of table \"list_item\""
input list_item_sum_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"columns and relationships of \"list_item_type\""
type list_item_type {
  description: String!
  "An array relationship"
  list_items("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "An aggregate relationship"
  list_items_aggregate("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): list_item_aggregate!
  name: String!
}

"aggregated selection of \"list_item_type\""
type list_item_type_aggregate {
  aggregate: list_item_type_aggregate_fields
  nodes: [list_item_type!]!
}

"aggregate fields of \"list_item_type\""
type list_item_type_aggregate_fields {
  count(columns: [list_item_type_select_column!] distinct: Boolean): Int!
  max: list_item_type_max_fields
  min: list_item_type_min_fields
}

"Boolean expression to filter rows from the table \"list_item_type\". All fields are combined with a logical 'AND'."
input list_item_type_bool_exp {
  _and: [list_item_type_bool_exp!]
  _not: list_item_type_bool_exp
  _or: [list_item_type_bool_exp!]
  description: String_comparison_exp
  list_items: list_item_bool_exp
  list_items_aggregate: list_item_aggregate_bool_exp
  name: String_comparison_exp
}

"unique or primary key constraints on table \"list_item_type\""
enum list_item_type_constraint {
  "unique or primary key constraint on columns \"name\""
  list_item_type_pkey
}

enum list_item_type_enum {
  "Generic item type for any URL list item"
  url
}

"Boolean expression to compare columns of type \"list_item_type_enum\". All fields are combined with logical 'AND'."
input list_item_type_enum_comparison_exp {
  _eq: list_item_type_enum
  _in: [list_item_type_enum!]
  _is_null: Boolean
  _neq: list_item_type_enum
  _nin: [list_item_type_enum!]
}

"input type for inserting data into table \"list_item_type\""
input list_item_type_insert_input {
  description: String
  list_items: list_item_arr_rel_insert_input
  name: String
}

"aggregate max on columns"
type list_item_type_max_fields {
  description: String
  name: String
}

"aggregate min on columns"
type list_item_type_min_fields {
  description: String
  name: String
}

"response of any mutation on the table \"list_item_type\""
type list_item_type_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [list_item_type!]!
}

"input type for inserting object relation for remote table \"list_item_type\""
input list_item_type_obj_rel_insert_input {
  data: list_item_type_insert_input!
  "upsert condition"
  on_conflict: list_item_type_on_conflict
}

"on_conflict condition type for table \"list_item_type\""
input list_item_type_on_conflict {
  constraint: list_item_type_constraint!
  update_columns: [list_item_type_update_column!]! = [  ]
  where: list_item_type_bool_exp
}

"Ordering options when selecting data from \"list_item_type\"."
input list_item_type_order_by {
  description: order_by
  list_items_aggregate: list_item_aggregate_order_by
  name: order_by
}

"primary key columns input for table: list_item_type"
input list_item_type_pk_columns_input {
  name: String!
}

"select columns of table \"list_item_type\""
enum list_item_type_select_column {
  "column name"
  description
  "column name"
  name
}

"input type for updating data in table \"list_item_type\""
input list_item_type_set_input {
  description: String
  name: String
}

"Streaming cursor of the table \"list_item_type\""
input list_item_type_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: list_item_type_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input list_item_type_stream_cursor_value_input {
  description: String
  name: String
}

"update columns of table \"list_item_type\""
enum list_item_type_update_column {
  "column name"
  description
  "column name"
  name
}

input list_item_type_updates {
  "sets the columns of the filtered rows to the given values"
  _set: list_item_type_set_input
  "filter the rows which have to be updated"
  where: list_item_type_bool_exp!
}

"update columns of table \"list_item\""
enum list_item_update_column {
  "column name"
  body
  "column name"
  created_at
  "column name"
  creator
  "column name"
  id
  "column name"
  list
  "column name"
  title
  "column name"
  type
  "column name"
  updated_at
}

input list_item_updates {
  "append existing jsonb value of filtered columns with new jsonb value"
  _append: list_item_append_input
  "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
  _delete_at_path: list_item_delete_at_path_input
  "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
  _delete_elem: list_item_delete_elem_input
  "delete key\/value pair or string element. key\/value pairs are matched based on their key value"
  _delete_key: list_item_delete_key_input
  "increments the numeric columns with given value of the filtered values"
  _inc: list_item_inc_input
  "prepend existing jsonb value of filtered columns with new jsonb value"
  _prepend: list_item_prepend_input
  "sets the columns of the filtered rows to the given values"
  _set: list_item_set_input
  "filter the rows which have to be updated"
  where: list_item_bool_exp!
}

"aggregate var_pop on columns"
type list_item_var_pop_fields {
  creator: Float
  id: Float
  list: Float
}

"order by var_pop() on columns of table \"list_item\""
input list_item_var_pop_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"aggregate var_samp on columns"
type list_item_var_samp_fields {
  creator: Float
  id: Float
  list: Float
}

"order by var_samp() on columns of table \"list_item\""
input list_item_var_samp_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"aggregate variance on columns"
type list_item_variance_fields {
  creator: Float
  id: Float
  list: Float
}

"order by variance() on columns of table \"list_item\""
input list_item_variance_order_by {
  creator: order_by
  id: order_by
  list: order_by
}

"aggregate max on columns"
type list_max_fields {
  created_at: timestamptz
  creator: bigint
  id: bigint
  title: String
  updated_at: timestamptz
}

"order by max() on columns of table \"list\""
input list_max_order_by {
  created_at: order_by
  creator: order_by
  id: order_by
  title: order_by
  updated_at: order_by
}

"aggregate min on columns"
type list_min_fields {
  created_at: timestamptz
  creator: bigint
  id: bigint
  title: String
  updated_at: timestamptz
}

"order by min() on columns of table \"list\""
input list_min_order_by {
  created_at: order_by
  creator: order_by
  id: order_by
  title: order_by
  updated_at: order_by
}

"response of any mutation on the table \"list\""
type list_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [list!]!
}

"input type for inserting object relation for remote table \"list\""
input list_obj_rel_insert_input {
  data: list_insert_input!
  "upsert condition"
  on_conflict: list_on_conflict
}

"on_conflict condition type for table \"list\""
input list_on_conflict {
  constraint: list_constraint!
  update_columns: [list_update_column!]! = [  ]
  where: list_bool_exp
}

"Ordering options when selecting data from \"list\"."
input list_order_by {
  created_at: order_by
  creator: order_by
  id: order_by
  list_items_aggregate: list_item_aggregate_order_by
  title: order_by
  updated_at: order_by
  user: user_order_by
}

"primary key columns input for table: list"
input list_pk_columns_input {
  id: bigint!
}

"select columns of table \"list\""
enum list_select_column {
  "column name"
  created_at
  "column name"
  creator
  "column name"
  id
  "column name"
  title
  "column name"
  updated_at
}

"input type for updating data in table \"list\""
input list_set_input {
  created_at: timestamptz
  creator: bigint
  id: bigint
  title: String
  updated_at: timestamptz
}

"aggregate stddev on columns"
type list_stddev_fields {
  creator: Float
  id: Float
}

"order by stddev() on columns of table \"list\""
input list_stddev_order_by {
  creator: order_by
  id: order_by
}

"aggregate stddev_pop on columns"
type list_stddev_pop_fields {
  creator: Float
  id: Float
}

"order by stddev_pop() on columns of table \"list\""
input list_stddev_pop_order_by {
  creator: order_by
  id: order_by
}

"aggregate stddev_samp on columns"
type list_stddev_samp_fields {
  creator: Float
  id: Float
}

"order by stddev_samp() on columns of table \"list\""
input list_stddev_samp_order_by {
  creator: order_by
  id: order_by
}

"Streaming cursor of the table \"list\""
input list_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: list_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input list_stream_cursor_value_input {
  created_at: timestamptz
  creator: bigint
  id: bigint
  title: String
  updated_at: timestamptz
}

"aggregate sum on columns"
type list_sum_fields {
  creator: bigint
  id: bigint
}

"order by sum() on columns of table \"list\""
input list_sum_order_by {
  creator: order_by
  id: order_by
}

"update columns of table \"list\""
enum list_update_column {
  "column name"
  created_at
  "column name"
  creator
  "column name"
  id
  "column name"
  title
  "column name"
  updated_at
}

input list_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: list_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: list_set_input
  "filter the rows which have to be updated"
  where: list_bool_exp!
}

"aggregate var_pop on columns"
type list_var_pop_fields {
  creator: Float
  id: Float
}

"order by var_pop() on columns of table \"list\""
input list_var_pop_order_by {
  creator: order_by
  id: order_by
}

"aggregate var_samp on columns"
type list_var_samp_fields {
  creator: Float
  id: Float
}

"order by var_samp() on columns of table \"list\""
input list_var_samp_order_by {
  creator: order_by
  id: order_by
}

"aggregate variance on columns"
type list_variance_fields {
  creator: Float
  id: Float
}

"order by variance() on columns of table \"list\""
input list_variance_order_by {
  creator: order_by
  id: order_by
}

"mutation root"
type mutation_root {
  "delete data from the table: \"flappy.high_score\""
  delete_flappy_high_score("filter the rows which have to be deleted" where: flappy_high_score_bool_exp!): flappy_high_score_mutation_response
  "delete single row from the table: \"flappy.high_score\""
  delete_flappy_high_score_by_pk(id: bigint!): flappy_high_score
  "delete data from the table: \"list\""
  delete_list("filter the rows which have to be deleted" where: list_bool_exp!): list_mutation_response
  "delete single row from the table: \"list\""
  delete_list_by_pk(id: bigint!): list
  "delete data from the table: \"list_item\""
  delete_list_item("filter the rows which have to be deleted" where: list_item_bool_exp!): list_item_mutation_response
  "delete single row from the table: \"list_item\""
  delete_list_item_by_pk(id: bigint!): list_item
  "delete data from the table: \"list_item_type\""
  delete_list_item_type("filter the rows which have to be deleted" where: list_item_type_bool_exp!): list_item_type_mutation_response
  "delete single row from the table: \"list_item_type\""
  delete_list_item_type_by_pk(name: String!): list_item_type
  "delete data from the table: \"user\""
  delete_user("filter the rows which have to be deleted" where: user_bool_exp!): user_mutation_response
  "delete single row from the table: \"user\""
  delete_user_by_pk(id: bigint!): user
  "insert data into the table: \"flappy.high_score\""
  insert_flappy_high_score("the rows to be inserted" objects: [flappy_high_score_insert_input!]! "upsert condition" on_conflict: flappy_high_score_on_conflict): flappy_high_score_mutation_response
  "insert a single row into the table: \"flappy.high_score\""
  insert_flappy_high_score_one("the row to be inserted" object: flappy_high_score_insert_input! "upsert condition" on_conflict: flappy_high_score_on_conflict): flappy_high_score
  "insert data into the table: \"list\""
  insert_list("the rows to be inserted" objects: [list_insert_input!]! "upsert condition" on_conflict: list_on_conflict): list_mutation_response
  "insert data into the table: \"list_item\""
  insert_list_item("the rows to be inserted" objects: [list_item_insert_input!]! "upsert condition" on_conflict: list_item_on_conflict): list_item_mutation_response
  "insert a single row into the table: \"list_item\""
  insert_list_item_one("the row to be inserted" object: list_item_insert_input! "upsert condition" on_conflict: list_item_on_conflict): list_item
  "insert data into the table: \"list_item_type\""
  insert_list_item_type("the rows to be inserted" objects: [list_item_type_insert_input!]! "upsert condition" on_conflict: list_item_type_on_conflict): list_item_type_mutation_response
  "insert a single row into the table: \"list_item_type\""
  insert_list_item_type_one("the row to be inserted" object: list_item_type_insert_input! "upsert condition" on_conflict: list_item_type_on_conflict): list_item_type
  "insert a single row into the table: \"list\""
  insert_list_one("the row to be inserted" object: list_insert_input! "upsert condition" on_conflict: list_on_conflict): list
  "insert data into the table: \"user\""
  insert_user("the rows to be inserted" objects: [user_insert_input!]! "upsert condition" on_conflict: user_on_conflict): user_mutation_response
  "insert a single row into the table: \"user\""
  insert_user_one("the row to be inserted" object: user_insert_input! "upsert condition" on_conflict: user_on_conflict): user
  "update data of the table: \"flappy.high_score\""
  update_flappy_high_score("increments the numeric columns with given value of the filtered values" _inc: flappy_high_score_inc_input "sets the columns of the filtered rows to the given values" _set: flappy_high_score_set_input "filter the rows which have to be updated" where: flappy_high_score_bool_exp!): flappy_high_score_mutation_response
  "update single row of the table: \"flappy.high_score\""
  update_flappy_high_score_by_pk("increments the numeric columns with given value of the filtered values" _inc: flappy_high_score_inc_input "sets the columns of the filtered rows to the given values" _set: flappy_high_score_set_input pk_columns: flappy_high_score_pk_columns_input!): flappy_high_score
  "update multiples rows of table: \"flappy.high_score\""
  update_flappy_high_score_many("updates to execute, in order" updates: [flappy_high_score_updates!]!): [flappy_high_score_mutation_response]
  "update data of the table: \"list\""
  update_list("increments the numeric columns with given value of the filtered values" _inc: list_inc_input "sets the columns of the filtered rows to the given values" _set: list_set_input "filter the rows which have to be updated" where: list_bool_exp!): list_mutation_response
  "update single row of the table: \"list\""
  update_list_by_pk("increments the numeric columns with given value of the filtered values" _inc: list_inc_input "sets the columns of the filtered rows to the given values" _set: list_set_input pk_columns: list_pk_columns_input!): list
  "update data of the table: \"list_item\""
  update_list_item("append existing jsonb value of filtered columns with new jsonb value" _append: list_item_append_input "delete the field or element with specified path (for JSON arrays, negative integers count from the end)" _delete_at_path: list_item_delete_at_path_input "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array" _delete_elem: list_item_delete_elem_input "delete key\/value pair or string element. key\/value pairs are matched based on their key value" _delete_key: list_item_delete_key_input "increments the numeric columns with given value of the filtered values" _inc: list_item_inc_input "prepend existing jsonb value of filtered columns with new jsonb value" _prepend: list_item_prepend_input "sets the columns of the filtered rows to the given values" _set: list_item_set_input "filter the rows which have to be updated" where: list_item_bool_exp!): list_item_mutation_response
  "update single row of the table: \"list_item\""
  update_list_item_by_pk("append existing jsonb value of filtered columns with new jsonb value" _append: list_item_append_input "delete the field or element with specified path (for JSON arrays, negative integers count from the end)" _delete_at_path: list_item_delete_at_path_input "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array" _delete_elem: list_item_delete_elem_input "delete key\/value pair or string element. key\/value pairs are matched based on their key value" _delete_key: list_item_delete_key_input "increments the numeric columns with given value of the filtered values" _inc: list_item_inc_input "prepend existing jsonb value of filtered columns with new jsonb value" _prepend: list_item_prepend_input "sets the columns of the filtered rows to the given values" _set: list_item_set_input pk_columns: list_item_pk_columns_input!): list_item
  "update multiples rows of table: \"list_item\""
  update_list_item_many("updates to execute, in order" updates: [list_item_updates!]!): [list_item_mutation_response]
  "update data of the table: \"list_item_type\""
  update_list_item_type("sets the columns of the filtered rows to the given values" _set: list_item_type_set_input "filter the rows which have to be updated" where: list_item_type_bool_exp!): list_item_type_mutation_response
  "update single row of the table: \"list_item_type\""
  update_list_item_type_by_pk("sets the columns of the filtered rows to the given values" _set: list_item_type_set_input pk_columns: list_item_type_pk_columns_input!): list_item_type
  "update multiples rows of table: \"list_item_type\""
  update_list_item_type_many("updates to execute, in order" updates: [list_item_type_updates!]!): [list_item_type_mutation_response]
  "update multiples rows of table: \"list\""
  update_list_many("updates to execute, in order" updates: [list_updates!]!): [list_mutation_response]
  "update data of the table: \"user\""
  update_user("increments the numeric columns with given value of the filtered values" _inc: user_inc_input "sets the columns of the filtered rows to the given values" _set: user_set_input "filter the rows which have to be updated" where: user_bool_exp!): user_mutation_response
  "update single row of the table: \"user\""
  update_user_by_pk("increments the numeric columns with given value of the filtered values" _inc: user_inc_input "sets the columns of the filtered rows to the given values" _set: user_set_input pk_columns: user_pk_columns_input!): user
  "update multiples rows of table: \"user\""
  update_user_many("updates to execute, in order" updates: [user_updates!]!): [user_mutation_response]
}

"column ordering options"
enum order_by {
  "in ascending order, nulls last"
  asc
  "in ascending order, nulls first"
  asc_nulls_first
  "in ascending order, nulls last"
  asc_nulls_last
  "in descending order, nulls first"
  desc
  "in descending order, nulls first"
  desc_nulls_first
  "in descending order, nulls last"
  desc_nulls_last
}

type query_root {
  "fetch data from the table: \"flappy.high_score\""
  flappy_high_score("distinct select on columns" distinct_on: [flappy_high_score_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [flappy_high_score_order_by!] "filter the rows returned" where: flappy_high_score_bool_exp): [flappy_high_score!]!
  "fetch aggregated fields from the table: \"flappy.high_score\""
  flappy_high_score_aggregate("distinct select on columns" distinct_on: [flappy_high_score_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [flappy_high_score_order_by!] "filter the rows returned" where: flappy_high_score_bool_exp): flappy_high_score_aggregate!
  "fetch data from the table: \"flappy.high_score\" using primary key columns"
  flappy_high_score_by_pk(id: bigint!): flappy_high_score
  "fetch data from the table: \"list\""
  list("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): [list!]!
  "fetch aggregated fields from the table: \"list\""
  list_aggregate("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): list_aggregate!
  "fetch data from the table: \"list\" using primary key columns"
  list_by_pk(id: bigint!): list
  "fetch data from the table: \"list_item\""
  list_item("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "fetch aggregated fields from the table: \"list_item\""
  list_item_aggregate("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): list_item_aggregate!
  "fetch data from the table: \"list_item\" using primary key columns"
  list_item_by_pk(id: bigint!): list_item
  "fetch data from the table: \"list_item_type\""
  list_item_type("distinct select on columns" distinct_on: [list_item_type_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_type_order_by!] "filter the rows returned" where: list_item_type_bool_exp): [list_item_type!]!
  "fetch aggregated fields from the table: \"list_item_type\""
  list_item_type_aggregate("distinct select on columns" distinct_on: [list_item_type_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_type_order_by!] "filter the rows returned" where: list_item_type_bool_exp): list_item_type_aggregate!
  "fetch data from the table: \"list_item_type\" using primary key columns"
  list_item_type_by_pk(name: String!): list_item_type
  "fetch data from the table: \"user\""
  user("distinct select on columns" distinct_on: [user_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [user_order_by!] "filter the rows returned" where: user_bool_exp): [user!]!
  "fetch aggregated fields from the table: \"user\""
  user_aggregate("distinct select on columns" distinct_on: [user_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [user_order_by!] "filter the rows returned" where: user_bool_exp): user_aggregate!
  "fetch data from the table: \"user\" using primary key columns"
  user_by_pk(id: bigint!): user
}

type subscription_root {
  "fetch data from the table: \"flappy.high_score\""
  flappy_high_score("distinct select on columns" distinct_on: [flappy_high_score_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [flappy_high_score_order_by!] "filter the rows returned" where: flappy_high_score_bool_exp): [flappy_high_score!]!
  "fetch aggregated fields from the table: \"flappy.high_score\""
  flappy_high_score_aggregate("distinct select on columns" distinct_on: [flappy_high_score_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [flappy_high_score_order_by!] "filter the rows returned" where: flappy_high_score_bool_exp): flappy_high_score_aggregate!
  "fetch data from the table: \"flappy.high_score\" using primary key columns"
  flappy_high_score_by_pk(id: bigint!): flappy_high_score
  "fetch data from the table in a streaming manner: \"flappy.high_score\""
  flappy_high_score_stream("maximum number of rows returned in a single batch" batch_size: Int! "cursor to stream the results returned by the query" cursor: [flappy_high_score_stream_cursor_input]! "filter the rows returned" where: flappy_high_score_bool_exp): [flappy_high_score!]!
  "fetch data from the table: \"list\""
  list("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): [list!]!
  "fetch aggregated fields from the table: \"list\""
  list_aggregate("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): list_aggregate!
  "fetch data from the table: \"list\" using primary key columns"
  list_by_pk(id: bigint!): list
  "fetch data from the table: \"list_item\""
  list_item("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "fetch aggregated fields from the table: \"list_item\""
  list_item_aggregate("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): list_item_aggregate!
  "fetch data from the table: \"list_item\" using primary key columns"
  list_item_by_pk(id: bigint!): list_item
  "fetch data from the table in a streaming manner: \"list_item\""
  list_item_stream("maximum number of rows returned in a single batch" batch_size: Int! "cursor to stream the results returned by the query" cursor: [list_item_stream_cursor_input]! "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "fetch data from the table: \"list_item_type\""
  list_item_type("distinct select on columns" distinct_on: [list_item_type_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_type_order_by!] "filter the rows returned" where: list_item_type_bool_exp): [list_item_type!]!
  "fetch aggregated fields from the table: \"list_item_type\""
  list_item_type_aggregate("distinct select on columns" distinct_on: [list_item_type_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_type_order_by!] "filter the rows returned" where: list_item_type_bool_exp): list_item_type_aggregate!
  "fetch data from the table: \"list_item_type\" using primary key columns"
  list_item_type_by_pk(name: String!): list_item_type
  "fetch data from the table in a streaming manner: \"list_item_type\""
  list_item_type_stream("maximum number of rows returned in a single batch" batch_size: Int! "cursor to stream the results returned by the query" cursor: [list_item_type_stream_cursor_input]! "filter the rows returned" where: list_item_type_bool_exp): [list_item_type!]!
  "fetch data from the table in a streaming manner: \"list\""
  list_stream("maximum number of rows returned in a single batch" batch_size: Int! "cursor to stream the results returned by the query" cursor: [list_stream_cursor_input]! "filter the rows returned" where: list_bool_exp): [list!]!
  "fetch data from the table: \"user\""
  user("distinct select on columns" distinct_on: [user_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [user_order_by!] "filter the rows returned" where: user_bool_exp): [user!]!
  "fetch aggregated fields from the table: \"user\""
  user_aggregate("distinct select on columns" distinct_on: [user_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [user_order_by!] "filter the rows returned" where: user_bool_exp): user_aggregate!
  "fetch data from the table: \"user\" using primary key columns"
  user_by_pk(id: bigint!): user
  "fetch data from the table in a streaming manner: \"user\""
  user_stream("maximum number of rows returned in a single batch" batch_size: Int! "cursor to stream the results returned by the query" cursor: [user_stream_cursor_input]! "filter the rows returned" where: user_bool_exp): [user!]!
}

scalar timestamptz

"Boolean expression to compare columns of type \"timestamptz\". All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

"columns and relationships of \"user\""
type user {
  created_at: timestamptz!
  id: bigint!
  last_seen: timestamptz
  "An array relationship"
  list_items("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): [list_item!]!
  "An aggregate relationship"
  list_items_aggregate("distinct select on columns" distinct_on: [list_item_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_item_order_by!] "filter the rows returned" where: list_item_bool_exp): list_item_aggregate!
  "An array relationship"
  lists("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): [list!]!
  "An aggregate relationship"
  lists_aggregate("distinct select on columns" distinct_on: [list_select_column!] "limit the number of rows returned" limit: Int "skip the first n rows. Use only with order_by" offset: Int "sort the rows by one or more columns" order_by: [list_order_by!] "filter the rows returned" where: list_bool_exp): list_aggregate!
  name_first: String!
  name_last: String!
  name_nick: String!
  updated_at: timestamptz
}

"aggregated selection of \"user\""
type user_aggregate {
  aggregate: user_aggregate_fields
  nodes: [user!]!
}

"aggregate fields of \"user\""
type user_aggregate_fields {
  avg: user_avg_fields
  count(columns: [user_select_column!] distinct: Boolean): Int!
  max: user_max_fields
  min: user_min_fields
  stddev: user_stddev_fields
  stddev_pop: user_stddev_pop_fields
  stddev_samp: user_stddev_samp_fields
  sum: user_sum_fields
  var_pop: user_var_pop_fields
  var_samp: user_var_samp_fields
  variance: user_variance_fields
}

"aggregate avg on columns"
type user_avg_fields {
  id: Float
}

"Boolean expression to filter rows from the table \"user\". All fields are combined with a logical 'AND'."
input user_bool_exp {
  _and: [user_bool_exp!]
  _not: user_bool_exp
  _or: [user_bool_exp!]
  created_at: timestamptz_comparison_exp
  id: bigint_comparison_exp
  last_seen: timestamptz_comparison_exp
  list_items: list_item_bool_exp
  list_items_aggregate: list_item_aggregate_bool_exp
  lists: list_bool_exp
  lists_aggregate: list_aggregate_bool_exp
  name_first: String_comparison_exp
  name_last: String_comparison_exp
  name_nick: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"unique or primary key constraints on table \"user\""
enum user_constraint {
  "unique or primary key constraint on columns \"id\""
  user_pkey
}

"input type for incrementing numeric columns in table \"user\""
input user_inc_input {
  id: bigint
}

"input type for inserting data into table \"user\""
input user_insert_input {
  created_at: timestamptz
  id: bigint
  last_seen: timestamptz
  list_items: list_item_arr_rel_insert_input
  lists: list_arr_rel_insert_input
  name_first: String
  name_last: String
  name_nick: String
  updated_at: timestamptz
}

"aggregate max on columns"
type user_max_fields {
  created_at: timestamptz
  id: bigint
  last_seen: timestamptz
  name_first: String
  name_last: String
  name_nick: String
  updated_at: timestamptz
}

"aggregate min on columns"
type user_min_fields {
  created_at: timestamptz
  id: bigint
  last_seen: timestamptz
  name_first: String
  name_last: String
  name_nick: String
  updated_at: timestamptz
}

"response of any mutation on the table \"user\""
type user_mutation_response {
  "number of rows affected by the mutation"
  affected_rows: Int!
  "data from the rows affected by the mutation"
  returning: [user!]!
}

"input type for inserting object relation for remote table \"user\""
input user_obj_rel_insert_input {
  data: user_insert_input!
  "upsert condition"
  on_conflict: user_on_conflict
}

"on_conflict condition type for table \"user\""
input user_on_conflict {
  constraint: user_constraint!
  update_columns: [user_update_column!]! = [  ]
  where: user_bool_exp
}

"Ordering options when selecting data from \"user\"."
input user_order_by {
  created_at: order_by
  id: order_by
  last_seen: order_by
  list_items_aggregate: list_item_aggregate_order_by
  lists_aggregate: list_aggregate_order_by
  name_first: order_by
  name_last: order_by
  name_nick: order_by
  updated_at: order_by
}

"primary key columns input for table: user"
input user_pk_columns_input {
  id: bigint!
}

"select columns of table \"user\""
enum user_select_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  last_seen
  "column name"
  name_first
  "column name"
  name_last
  "column name"
  name_nick
  "column name"
  updated_at
}

"input type for updating data in table \"user\""
input user_set_input {
  created_at: timestamptz
  id: bigint
  last_seen: timestamptz
  name_first: String
  name_last: String
  name_nick: String
  updated_at: timestamptz
}

"aggregate stddev on columns"
type user_stddev_fields {
  id: Float
}

"aggregate stddev_pop on columns"
type user_stddev_pop_fields {
  id: Float
}

"aggregate stddev_samp on columns"
type user_stddev_samp_fields {
  id: Float
}

"Streaming cursor of the table \"user\""
input user_stream_cursor_input {
  "Stream column input with initial value"
  initial_value: user_stream_cursor_value_input!
  "cursor ordering"
  ordering: cursor_ordering
}

"Initial value of the column from where the streaming should start"
input user_stream_cursor_value_input {
  created_at: timestamptz
  id: bigint
  last_seen: timestamptz
  name_first: String
  name_last: String
  name_nick: String
  updated_at: timestamptz
}

"aggregate sum on columns"
type user_sum_fields {
  id: bigint
}

"update columns of table \"user\""
enum user_update_column {
  "column name"
  created_at
  "column name"
  id
  "column name"
  last_seen
  "column name"
  name_first
  "column name"
  name_last
  "column name"
  name_nick
  "column name"
  updated_at
}

input user_updates {
  "increments the numeric columns with given value of the filtered values"
  _inc: user_inc_input
  "sets the columns of the filtered rows to the given values"
  _set: user_set_input
  "filter the rows which have to be updated"
  where: user_bool_exp!
}

"aggregate var_pop on columns"
type user_var_pop_fields {
  id: Float
}

"aggregate var_samp on columns"
type user_var_samp_fields {
  id: Float
}

"aggregate variance on columns"
type user_variance_fields {
  id: Float
}

"whether this query should be cached (Hasura Cloud only)"
directive @cached("measured in seconds" ttl: Int! = 60 "refresh the cache entry" refresh: Boolean! = false) on QUERY